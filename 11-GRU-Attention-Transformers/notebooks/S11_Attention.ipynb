{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S11_Attention.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qElzb09OiePe"},"source":["# ANNOTATED ENCODER-DECODER WITH ATTENTION\n","\n","This is implementation of Neural Language translator(German to English) using Attention Mechnism\n","\n","- Reference: https://bastings.github.io/annotated_encoder_decoder/"]},{"cell_type":"code","metadata":{"id":"85Yt689gGcL4","executionInfo":{"status":"ok","timestamp":1604082128034,"user_tz":-330,"elapsed":1425,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"30373de8-764f-46a9-960d-285bf25199f1","colab":{"base_uri":"https://localhost:8080/"}},"source":["# mount gdrive\n","mount_drive = True\n","if mount_drive:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive') "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H01QY-RKy7GB","executionInfo":{"status":"ok","timestamp":1604082129197,"user_tz":-330,"elapsed":2566,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"6d58a033-a6e9-4c6a-d600-cb1ac95ea45b","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","\n","# check the allocation machine\n","isCuda = torch.cuda.is_available()\n","machine = torch.cuda.get_device_properties(0) if isCuda else 'cpu'\n","print(\"Assigned Machine: \", machine)\n","device = torch.device('cuda:0' if isCuda else 'cpu')\n","print(f\"cuda avaiable: {isCuda}, Device: {device}\")\n","\n","DEVICE = device\n","USE_CUDA = isCuda"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Assigned Machine:  _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', major=7, minor=0, total_memory=16130MB, multi_processor_count=80)\n","cuda avaiable: True, Device: cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UJxS4zcay6-4","executionInfo":{"status":"ok","timestamp":1604082129198,"user_tz":-330,"elapsed":2554,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"c381af77-023e-4d7c-c005-60d91d45adb0","colab":{"base_uri":"https://localhost:8080/"}},"source":["import os\n","os.chdir('/content/gdrive/My Drive/TSAI/EVA4_Phase2/session11-GRU-Attention-Transformers/notebooks/')\n","print(os.getcwd())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/TSAI/EVA4_Phase2/session11-GRU-Attention-Transformers/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_FIuA690y67H","executionInfo":{"status":"ok","timestamp":1604082129200,"user_tz":-330,"elapsed":2546,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["# Import standard packages\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math, copy, time\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from IPython.core.debugger import set_trace\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_O3OzAOy628","executionInfo":{"status":"ok","timestamp":1604082129201,"user_tz":-330,"elapsed":2540,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["# To autoreload all te custom files when modified\n","import autoreload\n","%load_ext autoreload\n","%autoreload"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_MJzYydE_nT","executionInfo":{"status":"ok","timestamp":1604082129201,"user_tz":-330,"elapsed":2532,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["import shutil\n","#shutil.rmtree('./logs/logs_tmp')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"b-3vLC1RAo6x","executionInfo":{"status":"ok","timestamp":1604082129202,"user_tz":-330,"elapsed":2526,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["from pathlib import Path\n","\n","# important folders used in this application\n","\n","Path(f'logs').mkdir(exist_ok=True)\n","\n","SOLUTION_LOG_DIR = f\"logs/logs_tmp\"     # root directoy for all the log of this notebook\n","Path(f'./{SOLUTION_LOG_DIR}').mkdir(exist_ok=True)\n","\n","SAVED_MODELS_DIR = Path(f'./{SOLUTION_LOG_DIR}/saved_models') # location to save models\n","SAVED_MODELS_DIR.mkdir(exist_ok=True)\n","\n","SAVED_RESULTS_DIR = Path(f'./{SOLUTION_LOG_DIR}/saved_results')\n","SAVED_RESULTS_DIR.mkdir(exist_ok=True)\n","\n","PLOT_DIR = Path(f'./{SOLUTION_LOG_DIR}/doc_images')\n","PLOT_DIR.mkdir(exist_ok=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DAKk6Dp1y9C","executionInfo":{"status":"ok","timestamp":1604082129205,"user_tz":-330,"elapsed":2522,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["# Application specific configurations\n","config_params = dict(\n","    seed=1,\n","    batch_size=64,\n","    num_workers=6,\n","    epochs=100,\n","    upscale_factor=2 \n",")\n","\n","torch.manual_seed(config_params['seed'])\n","if isCuda:\n","   torch.cuda.manual_seed(config_params['seed'])"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xHRZtsVo-Aik"},"source":["# Model Class"]},{"cell_type":"markdown","metadata":{"id":"mm5DLYMf-kHK"},"source":["## EncoderDecoder Class"]},{"cell_type":"code","metadata":{"id":"ZEq3grlp9qrV","executionInfo":{"status":"ok","timestamp":1604082129206,"user_tz":-330,"elapsed":2517,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["class EncoderDecoder(nn.Module):\n","    \"\"\"\n","    A standard Encoder-Decoder architecture. Base for this and many \n","    other models.\n","    \"\"\"\n","    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n","        super(EncoderDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_embed = src_embed\n","        self.trg_embed = trg_embed\n","        self.generator = generator\n","        \n","    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n","        \"\"\"Take in and process masked src and target sequences.\"\"\"\n","        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n","        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n","    \n","    def encode(self, src, src_mask, src_lengths):\n","        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n","    \n","    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n","               decoder_hidden=None):\n","        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n","                            src_mask, trg_mask, hidden=decoder_hidden)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iWBouWOV-K1C"},"source":["## Generator\n","\n","**Generator class simply projects the pre-output layer (x in the forward function below) to obtain the output layer, so that the final dimension is the target vocabulary size.**"]},{"cell_type":"code","metadata":{"id":"aL1LXJsT9q0j","executionInfo":{"status":"ok","timestamp":1604082129207,"user_tz":-330,"elapsed":2511,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["class Generator(nn.Module):\n","    \"\"\"Define standard linear + softmax generation step.\"\"\"\n","    def __init__(self, hidden_size, vocab_size):\n","        super(Generator, self).__init__()\n","        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n","\n","    def forward(self, x):\n","        return F.log_softmax(self.proj(x), dim=-1)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hBoPPpC6-SQg"},"source":["## Encoder\n","\n","Encoder is bi-directional GRU"]},{"cell_type":"code","metadata":{"id":"ugj6La2q9q6B","executionInfo":{"status":"ok","timestamp":1604082129208,"user_tz":-330,"elapsed":2506,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["class Encoder(nn.Module):\n","    \"\"\"Encodes a sequence of word embeddings\"\"\"\n","    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n","        super(Encoder, self).__init__()\n","        self.num_layers = num_layers\n","        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n","                          batch_first=True, bidirectional=True, dropout=dropout)\n","        \n","    def forward(self, x, mask, lengths):\n","        \"\"\"\n","        Applies a bidirectional GRU to sequence of embeddings x.\n","        The input mini-batch x needs to be sorted by length.\n","        x should have dimensions [batch, time, dim].\n","        \"\"\"\n","        packed = pack_padded_sequence(x, lengths, batch_first=True)\n","        output, final = self.rnn(packed)\n","        output, _ = pad_packed_sequence(output, batch_first=True)\n","\n","        # we need to manually concatenate the final states for both directions\n","        fwd_final = final[0:final.size(0):2]\n","        bwd_final = final[1:final.size(0):2]\n","        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n","\n","        return output, final"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cJ5m3uQz-r30"},"source":["## Decoder\n","The decoder is a conditional GRU"]},{"cell_type":"code","metadata":{"id":"R46WQIfT9rEj","executionInfo":{"status":"ok","timestamp":1604082129208,"user_tz":-330,"elapsed":2500,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["class Decoder(nn.Module):\n","    \"\"\"A conditional RNN decoder with attention.\"\"\"\n","    \n","    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n","                 bridge=True):\n","        super(Decoder, self).__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.attention = attention\n","        self.dropout = dropout\n","                 \n","        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers,\n","                          batch_first=True, dropout=dropout)\n","                 \n","        # to initialize from the final encoder state\n","        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n","\n","        self.dropout_layer = nn.Dropout(p=dropout)\n","        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size,\n","                                          hidden_size, bias=False)\n","        \n","    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n","        \"\"\"Perform a single decoder step (1 word)\"\"\"\n","\n","        # compute context vector using attention mechanism\n","        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n","        context, attn_probs = self.attention(\n","            query=query, proj_key=proj_key,\n","            value=encoder_hidden, mask=src_mask)\n","\n","        # update rnn hidden state\n","        rnn_input = torch.cat([prev_embed, context], dim=2)\n","        output, hidden = self.rnn(rnn_input, hidden)\n","        \n","        pre_output = torch.cat([prev_embed, output, context], dim=2)\n","        pre_output = self.dropout_layer(pre_output)\n","        pre_output = self.pre_output_layer(pre_output)\n","\n","        return output, hidden, pre_output\n","    \n","    def forward(self, trg_embed, encoder_hidden, encoder_final, \n","                src_mask, trg_mask, hidden=None, max_len=None):\n","        \"\"\"Unroll the decoder one step at a time.\"\"\"\n","                                         \n","        # the maximum number of steps to unroll the RNN\n","        if max_len is None:\n","            max_len = trg_mask.size(-1)\n","\n","        # initialize decoder hidden state\n","        if hidden is None:\n","            hidden = self.init_hidden(encoder_final)\n","        \n","        # pre-compute projected encoder hidden states\n","        # (the \"keys\" for the attention mechanism)\n","        # this is only done for efficiency\n","        proj_key = self.attention.key_layer(encoder_hidden)\n","        \n","        # here we store all intermediate hidden states and pre-output vectors\n","        decoder_states = []\n","        pre_output_vectors = []\n","        \n","        # unroll the decoder RNN for max_len steps\n","        for i in range(max_len):\n","            prev_embed = trg_embed[:, i].unsqueeze(1)\n","            output, hidden, pre_output = self.forward_step(\n","              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n","            decoder_states.append(output)\n","            pre_output_vectors.append(pre_output)\n","\n","        decoder_states = torch.cat(decoder_states, dim=1)\n","        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n","        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n","\n","    def init_hidden(self, encoder_final):\n","        \"\"\"Returns the initial decoder state,\n","        conditioned on the final encoder state.\"\"\"\n","\n","        if encoder_final is None:\n","            return None  # start with zeros\n","\n","        return torch.tanh(self.bridge(encoder_final))   "],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zagZcZLM_GU1"},"source":["## Attention"]},{"cell_type":"code","metadata":{"id":"UzosGTFo9rR6","executionInfo":{"status":"ok","timestamp":1604082129209,"user_tz":-330,"elapsed":2495,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["class BahdanauAttention(nn.Module):\n","    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n","    \n","    def __init__(self, hidden_size, key_size=None, query_size=None):\n","        super(BahdanauAttention, self).__init__()\n","        \n","        # We assume a bi-directional encoder so key_size is 2*hidden_size\n","        key_size = 2 * hidden_size if key_size is None else key_size\n","        query_size = hidden_size if query_size is None else query_size\n","\n","        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n","        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n","        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n","        \n","        # to store attention scores\n","        self.alphas = None\n","        \n","    def forward(self, query=None, proj_key=None, value=None, mask=None):\n","        assert mask is not None, \"mask is required\"\n","\n","        # We first project the query (the decoder state).\n","        # The projected keys (the encoder states) were already pre-computated.\n","        query = self.query_layer(query)\n","        \n","        # Calculate scores.\n","        scores = self.energy_layer(torch.tanh(query + proj_key))\n","        scores = scores.squeeze(2).unsqueeze(1)\n","        \n","        # Mask out invalid positions.\n","        # The mask marks valid positions so we invert it using `mask & 0`.\n","        scores.data.masked_fill_(mask == 0, -float('inf'))\n","        \n","        # Turn scores to probabilities.\n","        alphas = F.softmax(scores, dim=-1)\n","        self.alphas = alphas        \n","        \n","        # The context vector is the weighted sum of the values.\n","        context = torch.bmm(alphas, value)\n","        \n","        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n","        return context, alphas"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ugV3MKg_ZOq"},"source":["## Full Model"]},{"cell_type":"code","metadata":{"id":"lIWUl5lv9rPB","executionInfo":{"status":"ok","timestamp":1604082129210,"user_tz":-330,"elapsed":2490,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n","    \"Helper: Construct a model from hyperparameters.\"\n","\n","    attention = BahdanauAttention(hidden_size)\n","\n","    model = EncoderDecoder(\n","        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n","        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n","        nn.Embedding(src_vocab, emb_size),\n","        nn.Embedding(tgt_vocab, emb_size),\n","        Generator(hidden_size, tgt_vocab))\n","\n","    return model.cuda() if USE_CUDA else model"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6PkRunb_y1T"},"source":["# Traning"]},{"cell_type":"markdown","metadata":{"id":"wJFi3H8T__eL"},"source":["## Batches and Masking"]},{"cell_type":"code","metadata":{"id":"WiW4sHPe9rMH","executionInfo":{"status":"ok","timestamp":1604082129210,"user_tz":-330,"elapsed":2482,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["class Batch:\n","    \"\"\"Object for holding a batch of data with mask during training.\n","    Input is a batch from a torch text iterator.\n","    \"\"\"\n","    def __init__(self, src, trg, pad_index=0):\n","        \n","        src, src_lengths = src\n","        \n","        self.src = src\n","        self.src_lengths = src_lengths\n","        self.src_mask = (src != pad_index).unsqueeze(-2)\n","        self.nseqs = src.size(0)\n","        \n","        self.trg = None\n","        self.trg_y = None\n","        self.trg_mask = None\n","        self.trg_lengths = None\n","        self.ntokens = None\n","\n","        if trg is not None:\n","            trg, trg_lengths = trg\n","            self.trg = trg[:, :-1]\n","            self.trg_lengths = trg_lengths\n","            self.trg_y = trg[:, 1:]\n","            self.trg_mask = (self.trg_y != pad_index)\n","            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n","        \n","        if USE_CUDA:\n","            self.src = self.src.cuda()\n","            self.src_mask = self.src_mask.cuda()\n","\n","            if trg is not None:\n","                self.trg = self.trg.cuda()\n","                self.trg_y = self.trg_y.cuda()\n","                self.trg_mask = self.trg_mask.cuda()"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qREeX76KAFB7"},"source":["## Training Loop"]},{"cell_type":"code","metadata":{"id":"bIPnDWdX9rJK","executionInfo":{"status":"ok","timestamp":1604082129211,"user_tz":-330,"elapsed":2477,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["def run_epoch(data_iter, model, loss_compute, print_every=50):\n","    \"\"\"Standard Training and Logging Function\"\"\"\n","\n","    start = time.time()\n","    total_tokens = 0\n","    total_loss = 0\n","    print_tokens = 0\n","\n","    for i, batch in enumerate(data_iter, 1):\n","        \n","        out, _, pre_output = model.forward(batch.src, batch.trg,\n","                                           batch.src_mask, batch.trg_mask,\n","                                           batch.src_lengths, batch.trg_lengths)\n","        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n","        total_loss += loss\n","        total_tokens += batch.ntokens\n","        print_tokens += batch.ntokens\n","        \n","        if model.training and i % print_every == 0:\n","            elapsed = time.time() - start\n","            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n","                    (i, loss / batch.nseqs, print_tokens / elapsed))\n","            start = time.time()\n","            print_tokens = 0\n","\n","    return math.exp(total_loss / float(total_tokens))"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KcLMssUhA937"},"source":["# IWSLT German-English Translation"]},{"cell_type":"code","metadata":{"id":"lqvHj15bBFXb","executionInfo":{"status":"ok","timestamp":1604082129212,"user_tz":-330,"elapsed":2470,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["#!pip install git+git://github.com/pytorch/text spacy \n","#!python -m spacy download en\n","#!python -m spacy download de"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AOfyiB0dGYhM"},"source":["## Loss Computation"]},{"cell_type":"code","metadata":{"id":"ELcWC3ZYGflM","executionInfo":{"status":"ok","timestamp":1604082129213,"user_tz":-330,"elapsed":2465,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["class SimpleLossCompute:\n","    \"\"\"A simple loss compute and train function.\"\"\"\n","\n","    def __init__(self, generator, criterion, opt=None):\n","        self.generator = generator\n","        self.criterion = criterion\n","        self.opt = opt\n","\n","    def __call__(self, x, y, norm):\n","        x = self.generator(x)\n","        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n","                              y.contiguous().view(-1))\n","        loss = loss / norm\n","\n","        if self.opt is not None:\n","            loss.backward()          \n","            self.opt.step()\n","            self.opt.zero_grad()\n","\n","        return loss.data.item() * norm"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lKUPhST4KMCk"},"source":["## Printing Functions\n","\n","To monitor progress during training, we will translate a few examples.\n","\n","We use greedy decoding for simplicity; that is, at each time step, starting at the first token, we choose the one with that maximum probability, and we never revisit that choice."]},{"cell_type":"code","metadata":{"id":"C9H_KnQeKPY_","executionInfo":{"status":"ok","timestamp":1604082129213,"user_tz":-330,"elapsed":2458,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n","    \"\"\"Greedily decode a sentence.\"\"\"\n","\n","    with torch.no_grad():\n","        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n","        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n","        trg_mask = torch.ones_like(prev_y)\n","\n","    output = []\n","    attention_scores = []\n","    hidden = None\n","\n","    for i in range(max_len):\n","        with torch.no_grad():\n","            out, hidden, pre_output = model.decode(\n","              encoder_hidden, encoder_final, src_mask,\n","              prev_y, trg_mask, hidden)\n","\n","            # we predict from the pre-output layer, which is\n","            # a combination of Decoder state, prev emb, and context\n","            prob = model.generator(pre_output[:, -1])\n","\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.data.item()\n","        output.append(next_word)\n","        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n","        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n","    \n","    output = np.array(output)\n","        \n","    # cut off everything starting from </s> \n","    # (only when eos_index provided)\n","    if eos_index is not None:\n","        first_eos = np.where(output==eos_index)[0]\n","        if len(first_eos) > 0:\n","            output = output[:first_eos[0]]      \n","    \n","    return output, np.concatenate(attention_scores, axis=1)\n","  \n","\n","def lookup_words(x, vocab=None):\n","    if vocab is not None:\n","        x = [vocab.itos[i] for i in x]\n","\n","    return [str(t) for t in x]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9voFLWQKPiY","executionInfo":{"status":"ok","timestamp":1604082129214,"user_tz":-330,"elapsed":2452,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["def print_examples(example_iter, model, n=2, max_len=100, \n","                   sos_index=1, \n","                   src_eos_index=None, \n","                   trg_eos_index=None, \n","                   src_vocab=None, trg_vocab=None):\n","    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n","\n","    model.eval()\n","    count = 0\n","    print()\n","    \n","    if src_vocab is not None and trg_vocab is not None:\n","        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n","        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n","        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n","    else:\n","        src_eos_index = None\n","        trg_sos_index = 1\n","        trg_eos_index = None\n","        \n","    for i, batch in enumerate(example_iter):\n","      \n","        src = batch.src.cpu().numpy()[0, :]\n","        trg = batch.trg_y.cpu().numpy()[0, :]\n","\n","        # remove </s> (if it is there)\n","        src = src[:-1] if src[-1] == src_eos_index else src\n","        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n","      \n","        result, _ = greedy_decode(\n","          model, batch.src, batch.src_mask, batch.src_lengths,\n","          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n","        print(\"Example #%d\" % (i+1))\n","        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n","        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n","        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n","        print()\n","        \n","        count += 1\n","        if count == n:\n","            break"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"5M8eOLUWLl4I","executionInfo":{"status":"ok","timestamp":1604082129656,"user_tz":-330,"elapsed":2888,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["def plot_perplexity(perplexities):\n","    \"\"\"plot perplexities\"\"\"\n","    plt.title(\"Perplexity per Epoch\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Perplexity\")\n","    plt.plot(perplexities)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lj-lpNnBBOG"},"source":["## Date loading\n","\n","load the dataset using torchtext and spacy for tokenization."]},{"cell_type":"code","metadata":{"id":"tQAvoRRuAJ0b","executionInfo":{"status":"ok","timestamp":1604082191406,"user_tz":-330,"elapsed":64632,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["# For data loading.\n","from torchtext import data, datasets\n","\n","if True:\n","    import spacy\n","    spacy_de = spacy.load('de')\n","    spacy_en = spacy.load('en')\n","\n","    def tokenize_de(text):\n","        return [tok.text for tok in spacy_de.tokenizer(text)]\n","\n","    def tokenize_en(text):\n","        return [tok.text for tok in spacy_en.tokenizer(text)]\n","\n","    UNK_TOKEN = \"<unk>\"\n","    PAD_TOKEN = \"<pad>\"    \n","    SOS_TOKEN = \"<s>\"\n","    EOS_TOKEN = \"</s>\"\n","    LOWER = True\n","    \n","    # we include lengths to provide to the RNNs\n","    SRC = data.Field(tokenize=tokenize_de, \n","                     batch_first=True, lower=LOWER, include_lengths=True,\n","                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n","    TRG = data.Field(tokenize=tokenize_en, \n","                     batch_first=True, lower=LOWER, include_lengths=True,\n","                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)\n","\n","    MAX_LEN = 25  # NOTE: we filter out a lot of sentences for speed\n","    train_data, valid_data, test_data = datasets.IWSLT.splits(\n","        exts=('.de', '.en'), fields=(SRC, TRG), \n","        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n","            len(vars(x)['trg']) <= MAX_LEN)\n","    MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n","    SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n","    TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n","    \n","    PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WfJWf1Q7BU-q"},"source":["Data Visualization"]},{"cell_type":"code","metadata":{"id":"lmwioqYIAKBg","executionInfo":{"status":"ok","timestamp":1604082191410,"user_tz":-330,"elapsed":64627,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"67a4cd3b-2252-4fc7-813e-2e6b67926303","colab":{"base_uri":"https://localhost:8080/"}},"source":["def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\n","    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n","\n","    print(\"Data set sizes (number of sentence pairs):\")\n","    print('train', len(train_data))\n","    print('valid', len(valid_data))\n","    print('test', len(test_data), \"\\n\")\n","\n","    print(\"First training example:\")\n","    print(\"src:\", \" \".join(vars(train_data[0])['src']))\n","    print(\"trg:\", \" \".join(vars(train_data[0])['trg']), \"\\n\")\n","\n","    print(\"Most common words (src):\")\n","    print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n","    print(\"Most common words (trg):\")\n","    print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\n","\n","    print(\"First 10 words (src):\")\n","    print(\"\\n\".join(\n","        '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n","    print(\"First 10 words (trg):\")\n","    print(\"\\n\".join(\n","        '%02d %s' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\n","\n","    print(\"Number of German words (types):\", len(src_field.vocab))\n","    print(\"Number of English words (types):\", len(trg_field.vocab), \"\\n\")\n","    \n","    \n","print_data_info(train_data, valid_data, test_data, SRC, TRG)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Data set sizes (number of sentence pairs):\n","train 143115\n","valid 690\n","test 963 \n","\n","First training example:\n","src: david gallo : das ist bill lange . ich bin dave gallo .\n","trg: david gallo : this is bill lange . i 'm dave gallo . \n","\n","Most common words (src):\n","         .     138329\n","         ,     105944\n","       und      41843\n","       die      40808\n","       das      33324\n","       sie      33034\n","       ich      31150\n","       ist      31037\n","        es      27449\n","       wir      25817 \n","\n","Most common words (trg):\n","         .     137259\n","         ,      91615\n","       the      73343\n","       and      50276\n","        to      42799\n","         a      39572\n","        of      39496\n","         i      33521\n","        it      32920\n","      that      32640 \n","\n","First 10 words (src):\n","00 <unk>\n","01 <pad>\n","02 </s>\n","03 .\n","04 ,\n","05 und\n","06 die\n","07 das\n","08 sie\n","09 ich \n","\n","First 10 words (trg):\n","00 <unk>\n","01 <pad>\n","02 <s>\n","03 </s>\n","04 .\n","05 ,\n","06 the\n","07 and\n","08 to\n","09 a \n","\n","Number of German words (types): 15765\n","Number of English words (types): 13002 \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f1ple9-0AKFh","executionInfo":{"status":"ok","timestamp":1604082191412,"user_tz":-330,"elapsed":64620,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["train_iter = data.BucketIterator(train_data, batch_size=64, train=True, \n","                                 sort_within_batch=True, \n","                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n","                                 device=DEVICE)\n","valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n","                           device=DEVICE)\n","\n","\n","def rebatch(pad_idx, batch):\n","    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n","    return Batch(batch.src, batch.trg, pad_idx)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CRbIPY2QBghu"},"source":["## Training the System"]},{"cell_type":"code","metadata":{"id":"p37GkR1oBf7A","executionInfo":{"status":"ok","timestamp":1604082191413,"user_tz":-330,"elapsed":64615,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["def train(model, num_epochs=10, lr=0.0003, print_every=100):\n","    \"\"\"Train a model on IWSLT\"\"\"\n","    \n","    if USE_CUDA:\n","        model.cuda()\n","\n","    # optionally add label smoothing; see the Annotated Transformer\n","    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n","    optim = torch.optim.Adam(model.parameters(), lr=lr)\n","    \n","    dev_perplexities = []\n","\n","    for epoch in range(num_epochs):\n","      \n","        print(\"Epoch\", epoch)\n","        model.train()\n","        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n","                                     model,\n","                                     SimpleLossCompute(model.generator, criterion, optim),\n","                                     print_every=print_every)\n","        \n","        model.eval()\n","        with torch.no_grad():\n","            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n","                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n","\n","            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n","                                       model, \n","                                       SimpleLossCompute(model.generator, criterion, None))\n","            print(\"Validation perplexity: %f\" % dev_perplexity)\n","            dev_perplexities.append(dev_perplexity)\n","        \n","    return dev_perplexities"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeObS7ObBgFI","executionInfo":{"status":"ok","timestamp":1604083148574,"user_tz":-330,"elapsed":1021769,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"106b0d08-00e2-48bb-e951-515e098283c2","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = make_model(len(SRC.vocab), len(TRG.vocab),\n","                   emb_size=256, hidden_size=256,\n","                   num_layers=1, dropout=0.2)\n","dev_perplexities = train(model, num_epochs=10, print_every=200)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 0\n","Epoch Step: 200 Loss: 116.449310 Tokens per Sec: 24159.586891\n","Epoch Step: 400 Loss: 71.665787 Tokens per Sec: 25130.503559\n","Epoch Step: 600 Loss: 74.421875 Tokens per Sec: 24879.045149\n","Epoch Step: 800 Loss: 47.276440 Tokens per Sec: 24366.847525\n","Epoch Step: 1000 Loss: 75.932198 Tokens per Sec: 24781.997125\n","Epoch Step: 1200 Loss: 29.180735 Tokens per Sec: 25110.865449\n","Epoch Step: 1400 Loss: 29.459829 Tokens per Sec: 24810.255343\n","Epoch Step: 1600 Loss: 44.592709 Tokens per Sec: 24833.609809\n","Epoch Step: 1800 Loss: 43.056980 Tokens per Sec: 24851.014800\n","Epoch Step: 2000 Loss: 21.248619 Tokens per Sec: 24828.280772\n","Epoch Step: 2200 Loss: 89.182846 Tokens per Sec: 24925.582145\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was eight years old , i was a <unk> of the <unk> of the <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father was on the <unk> , the <unk> of the <unk> of the <unk> .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he was very happy , what was a very interesting thing that was a <unk> , it was the <unk> .\n","\n","Validation perplexity: 31.810622\n","Epoch 1\n","Epoch Step: 200 Loss: 81.649155 Tokens per Sec: 24011.144657\n","Epoch Step: 400 Loss: 22.025436 Tokens per Sec: 24879.342134\n","Epoch Step: 600 Loss: 71.424286 Tokens per Sec: 24842.936674\n","Epoch Step: 800 Loss: 18.242174 Tokens per Sec: 24888.871836\n","Epoch Step: 1000 Loss: 51.037388 Tokens per Sec: 24872.101147\n","Epoch Step: 1200 Loss: 68.782906 Tokens per Sec: 25149.495708\n","Epoch Step: 1400 Loss: 17.999458 Tokens per Sec: 24872.283510\n","Epoch Step: 1600 Loss: 60.061520 Tokens per Sec: 24870.916727\n","Epoch Step: 1800 Loss: 56.947403 Tokens per Sec: 24766.737962\n","Epoch Step: 2000 Loss: 52.803768 Tokens per Sec: 24940.777810\n","Epoch Step: 2200 Loss: 47.978485 Tokens per Sec: 24846.268729\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was one of the <unk> of the <unk> <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father was on his <unk> , the <unk> , the <unk> of the <unk> of the <unk> .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was a very short thing that was the <unk> , and it was the <unk> of <unk> .\n","\n","Validation perplexity: 20.135023\n","Epoch 2\n","Epoch Step: 200 Loss: 28.528225 Tokens per Sec: 23776.673239\n","Epoch Step: 400 Loss: 69.674454 Tokens per Sec: 24789.563972\n","Epoch Step: 600 Loss: 66.260406 Tokens per Sec: 24855.730626\n","Epoch Step: 800 Loss: 38.463161 Tokens per Sec: 24706.010799\n","Epoch Step: 1000 Loss: 61.011013 Tokens per Sec: 24684.734285\n","Epoch Step: 1200 Loss: 35.310467 Tokens per Sec: 25024.979157\n","Epoch Step: 1400 Loss: 40.649990 Tokens per Sec: 24770.030035\n","Epoch Step: 1600 Loss: 45.262321 Tokens per Sec: 25088.664192\n","Epoch Step: 1800 Loss: 10.877699 Tokens per Sec: 24939.053322\n","Epoch Step: 2000 Loss: 38.023022 Tokens per Sec: 24839.931756\n","Epoch Step: 2200 Loss: 69.468979 Tokens per Sec: 24710.617177\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was a <unk> of the <unk> of joy .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father was on his little , the radio <unk> of the <unk> of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty much , which was a <unk> , which was the <unk> of <unk> .\n","\n","Validation perplexity: 15.391106\n","Epoch 3\n","Epoch Step: 200 Loss: 68.702705 Tokens per Sec: 23911.361656\n","Epoch Step: 400 Loss: 40.794968 Tokens per Sec: 24511.508057\n","Epoch Step: 600 Loss: 61.664570 Tokens per Sec: 24630.260234\n","Epoch Step: 800 Loss: 17.775896 Tokens per Sec: 24330.699226\n","Epoch Step: 1000 Loss: 62.970673 Tokens per Sec: 24444.933305\n","Epoch Step: 1200 Loss: 40.250797 Tokens per Sec: 24668.438902\n","Epoch Step: 1400 Loss: 23.330563 Tokens per Sec: 24315.339315\n","Epoch Step: 1600 Loss: 20.099277 Tokens per Sec: 24086.496320\n","Epoch Step: 1800 Loss: 66.109718 Tokens per Sec: 24228.179644\n","Epoch Step: 2000 Loss: 61.401833 Tokens per Sec: 24407.878031\n","Epoch Step: 2200 Loss: 35.599159 Tokens per Sec: 24578.167077\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was going to be a <unk> of the <unk> of the <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father was on his little , <unk> radio <unk> the <unk> of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty much when he was the <unk> of his <unk> .\n","\n","Validation perplexity: 13.637058\n","Epoch 4\n","Epoch Step: 200 Loss: 53.076580 Tokens per Sec: 23868.269720\n","Epoch Step: 400 Loss: 42.755795 Tokens per Sec: 24438.404753\n","Epoch Step: 600 Loss: 49.991997 Tokens per Sec: 24714.837705\n","Epoch Step: 800 Loss: 42.071106 Tokens per Sec: 24544.435530\n","Epoch Step: 1000 Loss: 40.101822 Tokens per Sec: 24141.207434\n","Epoch Step: 1200 Loss: 37.249615 Tokens per Sec: 24208.890264\n","Epoch Step: 1400 Loss: 38.796860 Tokens per Sec: 24292.027382\n","Epoch Step: 1600 Loss: 39.310558 Tokens per Sec: 24268.562475\n","Epoch Step: 1800 Loss: 34.659840 Tokens per Sec: 24364.519955\n","Epoch Step: 2000 Loss: 21.282402 Tokens per Sec: 24322.719711\n","Epoch Step: 2200 Loss: 22.262589 Tokens per Sec: 24665.401565\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was <unk> to the <unk> of the <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my dad was <unk> on his little , <unk> radio <unk> the <unk> of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty much when he was <unk> , who was the news of the news of the news .\n","\n","Validation perplexity: 12.703529\n","Epoch 5\n","Epoch Step: 200 Loss: 7.755609 Tokens per Sec: 23827.683473\n","Epoch Step: 400 Loss: 52.360619 Tokens per Sec: 24610.656178\n","Epoch Step: 600 Loss: 36.204842 Tokens per Sec: 24345.710904\n","Epoch Step: 800 Loss: 58.150349 Tokens per Sec: 24451.646945\n","Epoch Step: 1000 Loss: 30.054567 Tokens per Sec: 24386.504009\n","Epoch Step: 1200 Loss: 27.764133 Tokens per Sec: 24327.088880\n","Epoch Step: 1400 Loss: 47.908356 Tokens per Sec: 24346.203516\n","Epoch Step: 1600 Loss: 35.118858 Tokens per Sec: 24460.022386\n","Epoch Step: 1800 Loss: 28.282558 Tokens per Sec: 24580.031651\n","Epoch Step: 2000 Loss: 29.220692 Tokens per Sec: 24252.402802\n","Epoch Step: 2200 Loss: 26.672224 Tokens per Sec: 24198.868300\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was a <unk> of <unk> to the <unk> of the <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father heard on his little , <unk> radio radio the <unk> of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , and then at the time , was pretty unusual , there was the news of <unk> .\n","\n","Validation perplexity: 12.030742\n","Epoch 6\n","Epoch Step: 200 Loss: 32.186737 Tokens per Sec: 23236.328477\n","Epoch Step: 400 Loss: 55.130951 Tokens per Sec: 23222.024741\n","Epoch Step: 600 Loss: 28.550665 Tokens per Sec: 23354.370017\n","Epoch Step: 800 Loss: 6.818125 Tokens per Sec: 23310.001959\n","Epoch Step: 1000 Loss: 51.229004 Tokens per Sec: 23520.817409\n","Epoch Step: 1200 Loss: 26.348087 Tokens per Sec: 23464.288862\n","Epoch Step: 1400 Loss: 18.392952 Tokens per Sec: 23255.801220\n","Epoch Step: 1600 Loss: 2.707276 Tokens per Sec: 23297.023435\n","Epoch Step: 1800 Loss: 19.669060 Tokens per Sec: 23272.853280\n","Epoch Step: 2000 Loss: 49.199821 Tokens per Sec: 23550.637779\n","Epoch Step: 2200 Loss: 53.396111 Tokens per Sec: 22948.306337\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years old , i was going to be <unk> to the <unk> of the <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father heard on his little , <unk> radio radio the <unk> of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty unusual , who was the most famous <unk> .\n","\n","Validation perplexity: 11.905688\n","Epoch 7\n","Epoch Step: 200 Loss: 22.991695 Tokens per Sec: 22815.521869\n","Epoch Step: 400 Loss: 41.314377 Tokens per Sec: 23492.290803\n","Epoch Step: 600 Loss: 35.844135 Tokens per Sec: 23390.785535\n","Epoch Step: 800 Loss: 17.596691 Tokens per Sec: 23241.967753\n","Epoch Step: 1000 Loss: 48.527149 Tokens per Sec: 23461.771745\n","Epoch Step: 1200 Loss: 40.020836 Tokens per Sec: 23325.694274\n","Epoch Step: 1400 Loss: 34.417503 Tokens per Sec: 23396.492995\n","Epoch Step: 1600 Loss: 20.213953 Tokens per Sec: 23396.704222\n","Epoch Step: 1800 Loss: 30.136572 Tokens per Sec: 23437.892826\n","Epoch Step: 2000 Loss: 50.196369 Tokens per Sec: 23580.337361\n","Epoch Step: 2200 Loss: 32.358315 Tokens per Sec: 23553.432437\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years , i became a <unk> of the <unk> of joy .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my dad heard on his little <unk> , radio shack the <unk> of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty unusual , because he was sending news .\n","\n","Validation perplexity: 11.947684\n","Epoch 8\n","Epoch Step: 200 Loss: 30.211876 Tokens per Sec: 22912.275067\n","Epoch Step: 400 Loss: 8.820591 Tokens per Sec: 23376.618321\n","Epoch Step: 600 Loss: 21.122978 Tokens per Sec: 23519.353514\n","Epoch Step: 800 Loss: 45.313648 Tokens per Sec: 23344.311180\n","Epoch Step: 1000 Loss: 31.768345 Tokens per Sec: 23594.835732\n","Epoch Step: 1200 Loss: 26.779068 Tokens per Sec: 23304.621127\n","Epoch Step: 1400 Loss: 16.108112 Tokens per Sec: 23667.144346\n","Epoch Step: 1600 Loss: 26.632553 Tokens per Sec: 23653.760929\n","Epoch Step: 1800 Loss: 46.412071 Tokens per Sec: 23710.469662\n","Epoch Step: 2000 Loss: 27.531662 Tokens per Sec: 23850.801158\n","Epoch Step: 2200 Loss: 50.215805 Tokens per Sec: 23366.882459\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 years , i was able to know the morning of the <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my dad heard his <unk> on his little gray radio shack the <unk> of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty unusual , who was sending him initially .\n","\n","Validation perplexity: 11.988285\n","Epoch 9\n","Epoch Step: 200 Loss: 17.294476 Tokens per Sec: 23240.775842\n","Epoch Step: 400 Loss: 19.058449 Tokens per Sec: 23867.524417\n","Epoch Step: 600 Loss: 40.981327 Tokens per Sec: 23528.007549\n","Epoch Step: 800 Loss: 48.202957 Tokens per Sec: 23539.430777\n","Epoch Step: 1000 Loss: 23.848764 Tokens per Sec: 23638.339326\n","Epoch Step: 1200 Loss: 22.974609 Tokens per Sec: 23744.676537\n","Epoch Step: 1400 Loss: 17.150517 Tokens per Sec: 23560.972512\n","Epoch Step: 1600 Loss: 32.291622 Tokens per Sec: 23684.251550\n","Epoch Step: 1800 Loss: 28.807859 Tokens per Sec: 23752.080629\n","Epoch Step: 2000 Loss: 36.501842 Tokens per Sec: 23783.187575\n","Epoch Step: 2200 Loss: 30.279474 Tokens per Sec: 23777.741609\n","\n","Example #1\n","Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n","Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n","Pred:  when i was 11 , i was going to be able to be bright the <unk> of the <unk> .\n","\n","Example #2\n","Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n","Trg :  my father was listening to bbc news on his small , gray radio .\n","Pred:  my father heard on his little , <unk> radio shack the <unk> of the bbc .\n","\n","Example #3\n","Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n","Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n","Pred:  he saw very happy , which was pretty good at that time there was <unk> the news of the most beautiful .\n","\n","Validation perplexity: 12.045618\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-eXUhTLeBgCN","executionInfo":{"status":"ok","timestamp":1604083148585,"user_tz":-330,"elapsed":1021762,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"74f33534-5b25-49d6-973b-b06fec70a768","colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["plot_perplexity(dev_perplexities)"],"execution_count":27,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"zeqVsNutBvhx"},"source":["## Prediction and Evaluation"]},{"cell_type":"code","metadata":{"id":"9JYJQlHvMSvf","executionInfo":{"status":"ok","timestamp":1604083148592,"user_tz":-330,"elapsed":1021761,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["#!pip install torch sacrebleu"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVyfxdAOBuzW","executionInfo":{"status":"ok","timestamp":1604083148598,"user_tz":-330,"elapsed":1021757,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["import sacrebleu"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6MyX39DBu9x","executionInfo":{"status":"ok","timestamp":1604083148599,"user_tz":-330,"elapsed":1021751,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"57c1173c-dc10-4ca7-dc0a-a4ffc348af8c","colab":{"base_uri":"https://localhost:8080/"}},"source":["# this should result in a perfect BLEU of 100%\n","hypotheses = [\"this is a test\"]\n","references = [\"this is a test\"]\n","bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n","print(bleu)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["100.00000000000004\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WoMmS_qqBu6Z","executionInfo":{"status":"ok","timestamp":1604083148600,"user_tz":-330,"elapsed":1021742,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"dba96dfa-0464-4fcb-d2ea-4ca606613ca0","colab":{"base_uri":"https://localhost:8080/"}},"source":["# here the BLEU score will be lower, because some n-grams won't match\n","hypotheses = [\"this is a test\"]\n","references = [\"this is a fest\"]\n","bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n","print(bleu)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["22.360679774997894\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zlatr-tuCJ8z"},"source":["## Translate the validation set"]},{"cell_type":"code","metadata":{"id":"kf-e_4unBu30","executionInfo":{"status":"ok","timestamp":1604083168559,"user_tz":-330,"elapsed":1041691,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["hypotheses = []\n","alphas = []  # save the last attention scores\n","for batch in valid_iter:\n","  batch = rebatch(PAD_INDEX, batch)\n","  pred, attention = greedy_decode(\n","    model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n","    sos_index=TRG.vocab.stoi[SOS_TOKEN],\n","    eos_index=TRG.vocab.stoi[EOS_TOKEN])\n","  hypotheses.append(pred)\n","  alphas.append(attention)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"1szp8UUABf_x","executionInfo":{"status":"ok","timestamp":1604083168563,"user_tz":-330,"elapsed":1041688,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"9088f2a4-077f-48a9-b57c-5ba6a094c9be","colab":{"base_uri":"https://localhost:8080/"}},"source":["# we will still need to convert the indices to actual words!\n","hypotheses[0]"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  70,   11,   24, 1460,    5,   11,   24,   63,    8,   38,  254,\n","          8,   38, 2111,    6,    0,   10,    6,    0,    4])"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"i3zQbQxsCS1b","executionInfo":{"status":"ok","timestamp":1604083168566,"user_tz":-330,"elapsed":1041682,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"4f41542a-6df1-46b3-fcb6-4f1e075c40ee","colab":{"base_uri":"https://localhost:8080/"}},"source":["hypotheses = [lookup_words(x, TRG.vocab) for x in hypotheses]\n","hypotheses[0]"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['when',\n"," 'i',\n"," 'was',\n"," '11',\n"," ',',\n"," 'i',\n"," 'was',\n"," 'going',\n"," 'to',\n"," 'be',\n"," 'able',\n"," 'to',\n"," 'be',\n"," 'bright',\n"," 'the',\n"," '<unk>',\n"," 'of',\n"," 'the',\n"," '<unk>',\n"," '.']"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"ogXYdh08CS-y","executionInfo":{"status":"ok","timestamp":1604083168567,"user_tz":-330,"elapsed":1041673,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"c4dc875e-d9d7-4146-c639-3d723ca9990d","colab":{"base_uri":"https://localhost:8080/"}},"source":["# finally, the SacreBLEU raw scorer requires string input, so we convert the lists to strings\n","hypotheses = [\" \".join(x) for x in hypotheses]\n","print(len(hypotheses))\n","print(hypotheses[0])"],"execution_count":35,"outputs":[{"output_type":"stream","text":["690\n","when i was 11 , i was going to be able to be bright the <unk> of the <unk> .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RnokVQ8pCa55"},"source":["## Attention Visualization"]},{"cell_type":"code","metadata":{"id":"LX4mlIjPCY15","executionInfo":{"status":"ok","timestamp":1604083168569,"user_tz":-330,"elapsed":1041667,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["def plot_heatmap(src, trg, scores):\n","\n","    fig, ax = plt.subplots()\n","    heatmap = ax.pcolor(scores, cmap='viridis')\n","\n","    ax.set_xticklabels(trg, minor=False, rotation='vertical')\n","    ax.set_yticklabels(src, minor=False)\n","\n","    # put the major ticks at the middle of each cell\n","    # and the x-ticks on top\n","    ax.xaxis.tick_top()\n","    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n","    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n","    ax.invert_yaxis()\n","\n","    plt.colorbar(heatmap)\n","    plt.show()"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSmLkU1ACZAz","executionInfo":{"status":"ok","timestamp":1604083168575,"user_tz":-330,"elapsed":1041664,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}},"outputId":"b2efeb78-c378-4088-e504-5817874ea0f2","colab":{"base_uri":"https://localhost:8080/","height":342}},"source":["# This plots a chosen sentence, for which we saved the attention scores above.\n","idx = 5\n","src = valid_data[idx].src + [\"</s>\"]\n","trg = valid_data[idx].trg + [\"</s>\"]\n","pred = hypotheses[idx].split() + [\"</s>\"]\n","pred_att = alphas[idx][0].T[:, :len(pred)]\n","print(\"src\", src)\n","print(\"ref\", trg)\n","print(\"pred\", pred)\n","plot_heatmap(src, pred, pred_att)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["src ['\"', 'jetzt', 'kannst', 'du', 'auf', 'eine', 'richtige', 'schule', 'gehen', ',', '\"', 'sagte', 'er', '.', '</s>']\n","ref ['\"', 'you', 'can', 'go', 'to', 'a', 'real', 'school', 'now', ',', '\"', 'he', 'said', '.', '</s>']\n","pred ['\"', 'now', 'you', 'can', 'go', 'to', 'a', 'right', 'school', ',', '\"', 'he', 'said', '.', '</s>']\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"GxGw12sBCY9w","executionInfo":{"status":"ok","timestamp":1604083169103,"user_tz":-330,"elapsed":1042180,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["torch.save(model, f'{SAVED_MODELS_DIR}/attention_cuda.pt')"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"WIpcFxcdKJfk","executionInfo":{"status":"ok","timestamp":1604083169105,"user_tz":-330,"elapsed":1042176,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":["loaded_model = torch.load(f'{SAVED_MODELS_DIR}/attention_cuda.pt')"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"PA2v-KONALig","executionInfo":{"status":"ok","timestamp":1604083169106,"user_tz":-330,"elapsed":1042171,"user":{"displayName":"birender panwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXvkboH7hmSUmi_g_Nb16rTaj0-QGOI4Whk22xYQ=s64","userId":"06487236384774354156"}}},"source":[""],"execution_count":39,"outputs":[]}]}