{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S5_HPE_Pytorch_To_Onnx.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BirenderPanwar/tsai_eva4p2/blob/master/5-HumanPoseEstimation/notebooks/S5_HPE_Pytorch_To_Onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qElzb09OiePe",
        "colab_type": "text"
      },
      "source": [
        "# Simple Baseline for Human Pose Estimation and Tracking\n",
        "\n",
        "1. Pytorch Resnet50 model trained in MPII dataset is used.\n",
        "2. Model is converted into ONNX format\n",
        "3. ONNX model is quantized to reduce the model file size from 130MB to around 65MB\n",
        "\n",
        "## Reference Materials:\n",
        "1. https://github.com/Microsoft/human-pose-estimation.pytorch\n",
        "2. Paper: https://arxiv.org/pdf/1804.06208.pdf\n",
        "3. Model is downloaded from: https://onedrive.live.com/?authkey=%21AFkTgCsr3CT9%2D%5FA&id=56B9F9C97F261712%2110709&cid=56B9F9C97F261712\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Yt689gGcL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b38ea145-0e9f-4dd6-c646-188e2fca5032"
      },
      "source": [
        "# mount gdrive\n",
        "mount_drive = True\n",
        "if mount_drive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJxS4zcay6-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48e98446-5793-4f86-a977-01bd9ff54cbf"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/TSAI/EVA4_Phase2/session5/notebooks/')\n",
        "print(os.getcwd())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TSAI/EVA4_Phase2/session5/notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FIuA690y67H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import standard packages\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SAVhLMTlzE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic file to import for HPE\n",
        "import _init_paths # set the system path for './human-pose-estimation.pytorch/lib'\n",
        "from core.config import config\n",
        "from core.config import update_config\n",
        "import models"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_O3OzAOy628",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To autoreload all te custom files when modified\n",
        "import autoreload\n",
        "%load_ext autoreload\n",
        "%autoreload"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HypgZUmC4QHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Necessary files path\n",
        "HPE_ROOT = './human-pose-estimation.pytorch'\n",
        "CONFIG_FILE = f'./{HPE_ROOT}/experiments/mpii/resnet50/256x256_d256x3_adam_lr1e-3.yaml'\n",
        "MODEL_BASEPATH = f'./hpe_trained_model'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggWmbY4fjjT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# update the configutaion for HPE\n",
        "update_config(CONFIG_FILE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cxpWJpgjjbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1866747c-bcd8-4d2e-828c-33fdbd838c1f"
      },
      "source": [
        "# loading HPE pytorch model\n",
        "model = eval('models.'+config.MODEL.NAME+'.get_pose_net')(config, is_train=False)\n",
        "model.load_state_dict(torch.load(f'{MODEL_BASEPATH}/pose_resnet_50_256x256.pth.tar', map_location=torch.device('cpu')))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYsoOleSjXO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fxn to check model size\n",
        "get_model_size = lambda filename: os.path.getsize(filename)/1e6"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95KoNWK9kPaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7e18734-ddd5-47a1-ed97-8ed58021c420"
      },
      "source": [
        "model_path = f'{MODEL_BASEPATH}/pose_resnet_50_256x256_pytorch.pt'\n",
        "torch.save(model, model_path)\n",
        "print(f'Pytorch model size (MB): {get_model_size(model_path):0.2f}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pytorch model size (MB): 136.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECIdT-ERwIyl",
        "colab_type": "text"
      },
      "source": [
        "# Exporting pytorch model into ONNX format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4rdHw7IjmJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "39acf3a6-3f98-45ba-eeef-e62ee85febef"
      },
      "source": [
        "!pip install onnx onnxruntime"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (1.7.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from onnx) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx) (49.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj0Vzj2dkqtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.onnx\n",
        "\n",
        "batch_size = 1\n",
        "x = torch.randn(batch_size, 3, 256, 256, requires_grad=True)\n",
        "output = model(x)\n",
        "\n",
        "onnx_model_path = f'{MODEL_BASEPATH}/pose_resnet_50_256x256_onxx.onnx'\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model,                     # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  onnx_model_path,   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7PTrm0xohfA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36f8898e-3f81-4716-9cab-29b275cbb921"
      },
      "source": [
        "print(f'ONXX model size (MB): {get_model_size(onnx_model_path):0.2f}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ONXX model size (MB): 136.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g8ENiQ1wUyv",
        "colab_type": "text"
      },
      "source": [
        "# Quantizing onnx model to further reducing the model size for AWS Lambda fitness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6clb2-uk-D-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import onnx\n",
        "\n",
        "# Import the ONNX model\n",
        "onnx_model = onnx.load(onnx_model_path)\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEjuUQnokTwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from onnxruntime.quantization import quantize\n",
        "from onnxruntime.quantization import QuantizationMode\n",
        "\n",
        "onnx_quantized_model_path = f'{MODEL_BASEPATH}/pose_resnet_50_256x256_quantized.onnx'\n",
        "\n",
        "onnx_quantized_model = quantize(onnx_model, quantization_mode=QuantizationMode.IntegerOps, static=False)\n",
        "onnx.save(onnx_quantized_model, onnx_quantized_model_path)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN69vu7Xljr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4946309-a303-4896-a408-12a91fb9f5a2"
      },
      "source": [
        "print(f'ONXX Quantized model size (MB): {get_model_size(onnx_quantized_model_path):0.2f}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ONXX Quantized model size (MB): 65.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMZOkVp3kOsI",
        "colab_type": "text"
      },
      "source": [
        "### Refer S5_HPE_OnnxRuntime_Inferencing.ipynb notebook for inferencing the model using OnnxRuntime"
      ]
    }
  ]
}